2022-05-28 00:32:42,113 - INFO] DVC training
2022-05-28 00:32:42,113 - INFO] config : 
2022-05-28 00:32:42,113 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 00:35:41,260 - INFO] DVC training
2022-05-28 00:35:41,260 - INFO] config : 
2022-05-28 00:35:41,260 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 00:41:18,964 - INFO] DVC training
2022-05-28 00:41:18,964 - INFO] config : 
2022-05-28 00:41:18,964 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 00:49:17,967 - INFO] DVC training
2022-05-28 00:49:17,967 - INFO] config : 
2022-05-28 00:49:17,967 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 00:50:06,536 - INFO] DVC training
2022-05-28 00:50:06,536 - INFO] config : 
2022-05-28 00:50:06,536 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 00:50:39,064 - INFO] DVC training
2022-05-28 00:50:39,064 - INFO] config : 
2022-05-28 00:50:39,064 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 00:52:49,407 - INFO] DVC training
2022-05-28 00:52:49,407 - INFO] config : 
2022-05-28 00:52:49,407 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 00:53:28,660 - INFO] DVC training
2022-05-28 00:53:28,660 - INFO] config : 
2022-05-28 00:53:28,660 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 00:55:09,392 - INFO] DVC training
2022-05-28 00:55:09,392 - INFO] config : 
2022-05-28 00:55:09,392 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 00:55:58,763 - INFO] DVC training
2022-05-28 00:55:58,763 - INFO] config : 
2022-05-28 00:55:58,763 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 00:56:37,833 - INFO] DVC training
2022-05-28 00:56:37,833 - INFO] config : 
2022-05-28 00:56:37,833 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:02:11,857 - INFO] DVC training
2022-05-28 01:02:11,857 - INFO] config : 
2022-05-28 01:02:11,857 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:11:20,566 - INFO] DVC training
2022-05-28 01:11:20,566 - INFO] config : 
2022-05-28 01:11:20,566 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:12:56,271 - INFO] DVC training
2022-05-28 01:12:56,271 - INFO] config : 
2022-05-28 01:12:56,271 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:14:49,492 - INFO] DVC training
2022-05-28 01:14:49,492 - INFO] config : 
2022-05-28 01:14:49,492 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:15:49,941 - INFO] DVC training
2022-05-28 01:15:49,941 - INFO] config : 
2022-05-28 01:15:49,941 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:17:47,360 - INFO] DVC training
2022-05-28 01:17:47,360 - INFO] config : 
2022-05-28 01:17:47,360 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:21:54,207 - INFO] DVC training
2022-05-28 01:21:54,207 - INFO] config : 
2022-05-28 01:21:54,207 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:33:03,055 - INFO] DVC training
2022-05-28 01:33:03,056 - INFO] config : 
2022-05-28 01:33:03,056 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:36:44,471 - INFO] DVC training
2022-05-28 01:36:44,471 - INFO] config : 
2022-05-28 01:36:44,471 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:39:07,567 - INFO] DVC training
2022-05-28 01:39:07,567 - INFO] config : 
2022-05-28 01:39:07,567 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:40:02,475 - INFO] DVC training
2022-05-28 01:40:02,475 - INFO] config : 
2022-05-28 01:40:02,475 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:41:30,205 - INFO] DVC training
2022-05-28 01:41:30,206 - INFO] config : 
2022-05-28 01:41:30,206 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:44:34,908 - INFO] DVC training
2022-05-28 01:44:34,909 - INFO] config : 
2022-05-28 01:44:34,909 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:46:03,005 - INFO] DVC training
2022-05-28 01:46:03,005 - INFO] config : 
2022-05-28 01:46:03,005 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:47:38,148 - INFO] DVC training
2022-05-28 01:47:38,149 - INFO] config : 
2022-05-28 01:47:38,149 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 01:50:06,322 - INFO] DVC training
2022-05-28 01:50:06,322 - INFO] config : 
2022-05-28 01:50:06,322 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 02:03:39,514 - INFO] DVC training
2022-05-28 02:03:39,514 - INFO] config : 
2022-05-28 02:03:39,515 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 02:08:25,533 - INFO] DVC training
2022-05-28 02:08:25,533 - INFO] config : 
2022-05-28 02:08:25,533 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 02:11:29,505 - INFO] DVC training
2022-05-28 02:11:29,506 - INFO] config : 
2022-05-28 02:11:29,506 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 02:13:37,772 - INFO] DVC training
2022-05-28 02:13:37,772 - INFO] config : 
2022-05-28 02:13:37,772 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 02:15:20,805 - INFO] DVC training
2022-05-28 02:15:20,805 - INFO] config : 
2022-05-28 02:15:20,805 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 02:17:09,252 - INFO] DVC training
2022-05-28 02:17:09,252 - INFO] config : 
2022-05-28 02:17:09,252 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 02:17:51,123 - INFO] DVC training
2022-05-28 02:17:51,123 - INFO] config : 
2022-05-28 02:17:51,123 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 02:22:39,094 - INFO] DVC training
2022-05-28 02:22:39,095 - INFO] config : 
2022-05-28 02:22:39,095 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 02:23:42,959 - INFO] DVC training
2022-05-28 02:23:42,959 - INFO] config : 
2022-05-28 02:23:42,959 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 02:25:14,439 - INFO] DVC training
2022-05-28 02:25:14,439 - INFO] config : 
2022-05-28 02:25:14,439 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 02:26:14,618 - INFO] DVC training
2022-05-28 02:26:14,618 - INFO] config : 
2022-05-28 02:26:14,618 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 02:27:24,764 - INFO] DVC training
2022-05-28 02:27:24,764 - INFO] config : 
2022-05-28 02:27:24,764 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:01:15,446 - INFO] DVC training
2022-05-28 09:01:15,446 - INFO] config : 
2022-05-28 09:01:15,446 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:13:09,699 - INFO] DVC training
2022-05-28 09:13:09,699 - INFO] config : 
2022-05-28 09:13:09,699 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:19:08,964 - INFO] DVC training
2022-05-28 09:19:08,965 - INFO] config : 
2022-05-28 09:19:08,965 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:20:12,488 - INFO] DVC training
2022-05-28 09:20:12,488 - INFO] config : 
2022-05-28 09:20:12,488 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:24:28,271 - INFO] DVC training
2022-05-28 09:24:28,271 - INFO] config : 
2022-05-28 09:24:28,272 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:27:37,247 - INFO] DVC training
2022-05-28 09:27:37,247 - INFO] config : 
2022-05-28 09:27:37,247 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:30:39,587 - INFO] DVC training
2022-05-28 09:30:39,587 - INFO] config : 
2022-05-28 09:30:39,587 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:31:02,835 - INFO] DVC training
2022-05-28 09:31:02,835 - INFO] config : 
2022-05-28 09:31:02,835 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:32:01,564 - INFO] DVC training
2022-05-28 09:32:01,564 - INFO] config : 
2022-05-28 09:32:01,564 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:32:51,916 - INFO] DVC training
2022-05-28 09:32:51,916 - INFO] config : 
2022-05-28 09:32:51,916 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:33:59,468 - INFO] DVC training
2022-05-28 09:33:59,468 - INFO] config : 
2022-05-28 09:33:59,468 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:35:33,772 - INFO] DVC training
2022-05-28 09:35:33,772 - INFO] config : 
2022-05-28 09:35:33,772 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:36:47,493 - INFO] DVC training
2022-05-28 09:36:47,493 - INFO] config : 
2022-05-28 09:36:47,493 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:52:57,135 - INFO] DVC training
2022-05-28 09:52:57,135 - INFO] config : 
2022-05-28 09:52:57,135 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 09:53:53,283 - INFO] DVC training
2022-05-28 09:53:53,283 - INFO] config : 
2022-05-28 09:53:53,283 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 10:01:59,749 - INFO] DVC training
2022-05-28 10:01:59,749 - INFO] config : 
2022-05-28 10:01:59,749 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 10:05:09,889 - INFO] DVC training
2022-05-28 10:05:09,889 - INFO] config : 
2022-05-28 10:05:09,889 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 12:20:18,929 - INFO] Train Epoch : 00 Loss:	 0.078951	 lr:0.0001
2022-05-28 14:34:41,555 - INFO] Train Epoch : 01 Loss:	 0.099627	 lr:0.0001
2022-05-28 15:16:07,430 - INFO] DVC training
2022-05-28 15:16:07,431 - INFO] config : 
2022-05-28 15:16:07,431 - INFO] {
    "tot_epoch": 100,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 15:16:24,234 - INFO] Train Epoch : 00 Loss:	 2.162242	 lr:0.0001
2022-05-28 15:16:37,063 - INFO] Train Epoch : 01 Loss:	 2.285661	 lr:0.0001
2022-05-28 15:16:49,906 - INFO] Train Epoch : 02 Loss:	 1.002954	 lr:0.0001
2022-05-28 15:17:03,060 - INFO] Train Epoch : 03 Loss:	 2.199554	 lr:0.0001
2022-05-28 15:17:16,225 - INFO] Train Epoch : 04 Loss:	 0.984584	 lr:0.0001
2022-05-28 15:17:29,470 - INFO] Train Epoch : 05 Loss:	 1.140359	 lr:0.0001
2022-05-28 15:17:42,753 - INFO] Train Epoch : 06 Loss:	 0.779338	 lr:0.0001
2022-05-28 15:17:55,895 - INFO] Train Epoch : 07 Loss:	 1.074468	 lr:0.0001
2022-05-28 15:18:09,199 - INFO] Train Epoch : 08 Loss:	 0.632495	 lr:0.0001
2022-05-28 15:18:22,659 - INFO] Train Epoch : 09 Loss:	 1.017286	 lr:0.0001
2022-05-28 15:18:35,858 - INFO] Train Epoch : 10 Loss:	 0.846201	 lr:0.0001
2022-05-28 15:18:49,105 - INFO] Train Epoch : 11 Loss:	 1.120808	 lr:0.0001
2022-05-28 15:19:02,243 - INFO] Train Epoch : 12 Loss:	 0.505715	 lr:0.0001
2022-05-28 15:19:15,536 - INFO] Train Epoch : 13 Loss:	 0.909779	 lr:0.0001
2022-05-28 15:19:28,813 - INFO] Train Epoch : 14 Loss:	 0.678710	 lr:0.0001
2022-05-28 15:19:41,933 - INFO] Train Epoch : 15 Loss:	 0.862698	 lr:0.0001
2022-05-28 15:19:55,111 - INFO] Train Epoch : 16 Loss:	 0.688363	 lr:0.0001
2022-05-28 15:20:08,244 - INFO] Train Epoch : 17 Loss:	 0.796647	 lr:0.0001
2022-05-28 15:20:21,490 - INFO] Train Epoch : 18 Loss:	 0.493603	 lr:0.0001
2022-05-28 15:20:34,760 - INFO] Train Epoch : 19 Loss:	 0.814590	 lr:0.0001
2022-05-28 15:20:47,929 - INFO] Train Epoch : 20 Loss:	 0.375599	 lr:0.0001
2022-05-28 15:21:01,163 - INFO] Train Epoch : 21 Loss:	 0.554112	 lr:0.0001
2022-05-28 15:21:14,158 - INFO] Train Epoch : 22 Loss:	 0.360228	 lr:0.0001
2022-05-28 15:21:27,323 - INFO] Train Epoch : 23 Loss:	 0.514441	 lr:0.0001
2022-05-28 15:21:40,521 - INFO] Train Epoch : 24 Loss:	 0.373470	 lr:0.0001
2022-05-28 15:21:53,760 - INFO] Train Epoch : 25 Loss:	 0.512428	 lr:0.0001
2022-05-28 15:22:06,729 - INFO] Train Epoch : 26 Loss:	 0.503371	 lr:0.0001
2022-05-28 15:22:19,844 - INFO] Train Epoch : 27 Loss:	 0.633398	 lr:0.0001
2022-05-28 15:22:33,030 - INFO] Train Epoch : 28 Loss:	 0.227898	 lr:0.0001
2022-05-28 15:22:46,277 - INFO] Train Epoch : 29 Loss:	 0.290526	 lr:0.0001
2022-05-28 15:22:59,544 - INFO] Train Epoch : 30 Loss:	 0.271387	 lr:0.0001
2022-05-28 15:23:12,886 - INFO] Train Epoch : 31 Loss:	 0.658902	 lr:0.0001
2022-05-28 15:23:26,204 - INFO] Train Epoch : 32 Loss:	 0.419784	 lr:0.0001
2022-05-28 15:23:39,457 - INFO] Train Epoch : 33 Loss:	 0.532825	 lr:0.0001
2022-05-28 15:23:52,758 - INFO] Train Epoch : 34 Loss:	 0.294697	 lr:0.0001
2022-05-28 15:24:05,994 - INFO] Train Epoch : 35 Loss:	 0.555504	 lr:0.0001
2022-05-28 15:24:19,255 - INFO] Train Epoch : 36 Loss:	 0.205689	 lr:0.0001
2022-05-28 15:24:32,492 - INFO] Train Epoch : 37 Loss:	 0.287550	 lr:0.0001
2022-05-28 15:24:45,715 - INFO] Train Epoch : 38 Loss:	 0.403999	 lr:0.0001
2022-05-28 15:24:58,975 - INFO] Train Epoch : 39 Loss:	 0.351143	 lr:0.0001
2022-05-28 15:25:12,239 - INFO] Train Epoch : 40 Loss:	 0.385511	 lr:0.0001
2022-05-28 15:25:25,470 - INFO] Train Epoch : 41 Loss:	 0.411888	 lr:0.0001
2022-05-28 15:25:38,726 - INFO] Train Epoch : 42 Loss:	 0.397007	 lr:0.0001
2022-05-28 15:25:52,040 - INFO] Train Epoch : 43 Loss:	 0.343031	 lr:0.0001
2022-05-28 15:26:05,316 - INFO] Train Epoch : 44 Loss:	 0.308018	 lr:0.0001
2022-05-28 15:26:18,554 - INFO] Train Epoch : 45 Loss:	 0.375327	 lr:0.0001
2022-05-28 15:26:31,746 - INFO] Train Epoch : 46 Loss:	 0.274451	 lr:0.0001
2022-05-28 15:26:45,012 - INFO] Train Epoch : 47 Loss:	 0.353362	 lr:0.0001
2022-05-28 15:26:58,351 - INFO] Train Epoch : 48 Loss:	 0.241276	 lr:0.0001
2022-05-28 15:27:11,641 - INFO] Train Epoch : 49 Loss:	 0.315194	 lr:0.0001
2022-05-28 15:27:24,938 - INFO] Train Epoch : 50 Loss:	 0.257006	 lr:0.0001
2022-05-28 15:27:38,223 - INFO] Train Epoch : 51 Loss:	 0.255930	 lr:0.0001
2022-05-28 15:27:51,481 - INFO] Train Epoch : 52 Loss:	 0.265451	 lr:0.0001
2022-05-28 15:28:04,816 - INFO] Train Epoch : 53 Loss:	 0.293296	 lr:0.0001
2022-05-28 15:28:17,922 - INFO] Train Epoch : 54 Loss:	 0.181870	 lr:0.0001
2022-05-28 15:28:31,078 - INFO] Train Epoch : 55 Loss:	 0.499605	 lr:0.0001
2022-05-28 15:28:44,437 - INFO] Train Epoch : 56 Loss:	 0.306884	 lr:0.0001
2022-05-28 15:28:57,717 - INFO] Train Epoch : 57 Loss:	 0.350106	 lr:0.0001
2022-05-28 15:29:10,970 - INFO] Train Epoch : 58 Loss:	 0.198258	 lr:0.0001
2022-05-28 15:29:24,168 - INFO] Train Epoch : 59 Loss:	 0.367055	 lr:0.0001
2022-05-28 15:29:37,454 - INFO] Train Epoch : 60 Loss:	 0.188982	 lr:0.0001
2022-05-28 15:29:50,717 - INFO] Train Epoch : 61 Loss:	 0.373242	 lr:0.0001
2022-05-28 15:30:03,811 - INFO] Train Epoch : 62 Loss:	 0.258752	 lr:0.0001
2022-05-28 15:30:17,043 - INFO] Train Epoch : 63 Loss:	 0.353199	 lr:0.0001
2022-05-28 15:30:30,390 - INFO] Train Epoch : 64 Loss:	 0.172186	 lr:0.0001
2022-05-28 15:30:43,758 - INFO] Train Epoch : 65 Loss:	 0.209293	 lr:0.0001
2022-05-28 15:30:56,882 - INFO] Train Epoch : 66 Loss:	 0.255212	 lr:0.0001
2022-05-28 15:31:10,130 - INFO] Train Epoch : 67 Loss:	 0.259871	 lr:0.0001
2022-05-28 15:31:23,468 - INFO] Train Epoch : 68 Loss:	 0.132387	 lr:0.0001
2022-05-28 15:31:36,730 - INFO] Train Epoch : 69 Loss:	 0.290803	 lr:0.0001
2022-05-28 15:31:49,999 - INFO] Train Epoch : 70 Loss:	 0.219846	 lr:0.0001
2022-05-28 15:32:03,372 - INFO] Train Epoch : 71 Loss:	 0.332170	 lr:0.0001
2022-05-28 15:32:16,609 - INFO] Train Epoch : 72 Loss:	 0.166532	 lr:0.0001
2022-05-28 15:32:29,953 - INFO] Train Epoch : 73 Loss:	 0.248450	 lr:0.0001
2022-05-28 15:32:43,244 - INFO] Train Epoch : 74 Loss:	 0.127118	 lr:0.0001
2022-05-28 15:32:56,444 - INFO] Train Epoch : 75 Loss:	 0.202355	 lr:0.0001
2022-05-28 15:33:09,731 - INFO] Train Epoch : 76 Loss:	 0.212011	 lr:0.0001
2022-05-28 15:33:22,969 - INFO] Train Epoch : 77 Loss:	 0.193862	 lr:0.0001
2022-05-28 15:33:36,351 - INFO] Train Epoch : 78 Loss:	 0.201612	 lr:0.0001
2022-05-28 15:33:49,630 - INFO] Train Epoch : 79 Loss:	 0.176942	 lr:0.0001
2022-05-28 15:34:02,967 - INFO] Train Epoch : 80 Loss:	 0.119072	 lr:0.0001
2022-05-28 15:34:16,285 - INFO] Train Epoch : 81 Loss:	 0.241053	 lr:0.0001
2022-05-28 15:34:29,607 - INFO] Train Epoch : 82 Loss:	 0.196860	 lr:0.0001
2022-05-28 15:34:42,994 - INFO] Train Epoch : 83 Loss:	 0.245409	 lr:0.0001
2022-05-28 15:34:56,265 - INFO] Train Epoch : 84 Loss:	 0.177892	 lr:0.0001
2022-05-28 15:35:09,508 - INFO] Train Epoch : 85 Loss:	 0.319907	 lr:0.0001
2022-05-28 15:35:22,849 - INFO] Train Epoch : 86 Loss:	 0.120468	 lr:0.0001
2022-05-28 15:35:36,190 - INFO] Train Epoch : 87 Loss:	 0.352185	 lr:0.0001
2022-05-28 15:35:49,544 - INFO] Train Epoch : 88 Loss:	 0.132877	 lr:0.0001
2022-05-28 15:36:02,905 - INFO] Train Epoch : 89 Loss:	 0.295815	 lr:0.0001
2022-05-28 15:36:16,238 - INFO] Train Epoch : 90 Loss:	 0.253231	 lr:0.0001
2022-05-28 15:36:29,558 - INFO] Train Epoch : 91 Loss:	 0.186390	 lr:0.0001
2022-05-28 15:36:42,888 - INFO] Train Epoch : 92 Loss:	 0.147636	 lr:0.0001
2022-05-28 15:36:56,202 - INFO] Train Epoch : 93 Loss:	 0.216326	 lr:0.0001
2022-05-28 15:37:09,523 - INFO] Train Epoch : 94 Loss:	 0.150281	 lr:0.0001
2022-05-28 15:37:22,910 - INFO] Train Epoch : 95 Loss:	 0.226537	 lr:0.0001
2022-05-28 15:37:36,218 - INFO] Train Epoch : 96 Loss:	 0.190415	 lr:0.0001
2022-05-28 15:37:49,428 - INFO] Train Epoch : 97 Loss:	 0.255424	 lr:0.0001
2022-05-28 15:38:02,717 - INFO] Train Epoch : 98 Loss:	 0.102668	 lr:0.0001
2022-05-28 15:38:16,079 - INFO] Train Epoch : 99 Loss:	 0.225803	 lr:0.0001
2022-05-28 15:40:25,929 - INFO] DVC training
2022-05-28 15:40:25,929 - INFO] config : 
2022-05-28 15:40:25,929 - INFO] {
    "tot_epoch": 200,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 15:41:59,221 - INFO] DVC training
2022-05-28 15:41:59,221 - INFO] config : 
2022-05-28 15:41:59,221 - INFO] {
    "tot_epoch": 200,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-28 15:44:07,938 - INFO] Train Epoch : 00 Loss:	 0.953094	 lr:0.0001
2022-05-28 15:46:15,740 - INFO] Train Epoch : 01 Loss:	 0.428849	 lr:0.0001
2022-05-28 15:48:25,320 - INFO] Train Epoch : 02 Loss:	 0.360132	 lr:0.0001
2022-05-28 15:50:33,699 - INFO] Train Epoch : 03 Loss:	 0.400603	 lr:0.0001
2022-05-28 15:52:40,926 - INFO] Train Epoch : 04 Loss:	 0.291381	 lr:0.0001
2022-05-28 15:54:48,482 - INFO] Train Epoch : 05 Loss:	 0.307915	 lr:0.0001
2022-05-28 15:56:58,237 - INFO] Train Epoch : 06 Loss:	 0.248341	 lr:0.0001
2022-05-28 15:59:08,092 - INFO] Train Epoch : 07 Loss:	 0.245721	 lr:0.0001
2022-05-28 16:01:16,158 - INFO] Train Epoch : 08 Loss:	 0.186025	 lr:0.0001
2022-05-28 16:03:23,598 - INFO] Train Epoch : 09 Loss:	 0.262264	 lr:0.0001
2022-05-28 16:05:31,283 - INFO] Train Epoch : 10 Loss:	 0.186049	 lr:0.0001
2022-05-28 16:07:39,054 - INFO] Train Epoch : 11 Loss:	 0.153838	 lr:0.0001
2022-05-28 16:09:45,873 - INFO] Train Epoch : 12 Loss:	 0.154469	 lr:0.0001
2022-05-28 16:11:52,201 - INFO] Train Epoch : 13 Loss:	 0.248849	 lr:0.0001
2022-05-28 16:14:01,873 - INFO] Train Epoch : 14 Loss:	 0.184588	 lr:0.0001
2022-05-28 16:16:09,641 - INFO] Train Epoch : 15 Loss:	 0.190628	 lr:0.0001
2022-05-28 16:18:17,521 - INFO] Train Epoch : 16 Loss:	 0.204665	 lr:0.0001
2022-05-28 16:20:25,501 - INFO] Train Epoch : 17 Loss:	 0.144812	 lr:0.0001
2022-05-28 16:22:33,540 - INFO] Train Epoch : 18 Loss:	 0.160556	 lr:0.0001
2022-05-28 16:24:41,382 - INFO] Train Epoch : 19 Loss:	 0.173224	 lr:0.0001
2022-05-28 16:26:50,361 - INFO] Train Epoch : 20 Loss:	 0.151232	 lr:0.0001
2022-05-28 16:28:58,260 - INFO] Train Epoch : 21 Loss:	 0.141677	 lr:0.0001
2022-05-28 16:31:07,069 - INFO] Train Epoch : 22 Loss:	 0.171936	 lr:0.0001
2022-05-28 16:33:16,745 - INFO] Train Epoch : 23 Loss:	 0.162930	 lr:0.0001
2022-05-28 16:35:26,073 - INFO] Train Epoch : 24 Loss:	 0.146296	 lr:0.0001
2022-05-28 16:37:33,971 - INFO] Train Epoch : 25 Loss:	 0.135157	 lr:0.0001
2022-05-28 16:39:43,828 - INFO] Train Epoch : 26 Loss:	 0.165987	 lr:0.0001
2022-05-28 16:41:51,270 - INFO] Train Epoch : 27 Loss:	 0.120233	 lr:0.0001
2022-05-28 16:43:59,435 - INFO] Train Epoch : 28 Loss:	 0.142701	 lr:0.0001
2022-05-28 16:46:08,857 - INFO] Train Epoch : 29 Loss:	 0.136470	 lr:0.0001
2022-05-28 16:48:16,445 - INFO] Train Epoch : 30 Loss:	 0.145022	 lr:0.0001
2022-05-28 16:50:24,452 - INFO] Train Epoch : 31 Loss:	 0.176628	 lr:0.0001
2022-05-28 16:52:31,346 - INFO] Train Epoch : 32 Loss:	 0.135797	 lr:0.0001
2022-05-28 16:54:39,011 - INFO] Train Epoch : 33 Loss:	 0.124280	 lr:0.0001
2022-05-28 16:56:47,213 - INFO] Train Epoch : 34 Loss:	 0.108456	 lr:0.0001
2022-05-28 16:58:54,790 - INFO] Train Epoch : 35 Loss:	 0.121964	 lr:0.0001
2022-05-28 17:01:03,858 - INFO] Train Epoch : 36 Loss:	 0.137057	 lr:0.0001
2022-05-29 00:41:03,369 - INFO] DVC training
2022-05-29 00:41:03,369 - INFO] config : 
2022-05-29 00:41:03,369 - INFO] {
    "tot_epoch": 200,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-05-29 00:43:12,844 - INFO] Train Epoch : 00 Loss:	 0.795876	 lr:0.0001
2022-05-29 00:45:19,073 - INFO] Train Epoch : 01 Loss:	 0.574063	 lr:0.0001
2022-05-29 00:47:27,577 - INFO] Train Epoch : 02 Loss:	 0.333469	 lr:0.0001
2022-05-29 00:49:35,485 - INFO] Train Epoch : 03 Loss:	 0.380488	 lr:0.0001
2022-05-29 00:51:44,369 - INFO] Train Epoch : 04 Loss:	 0.286016	 lr:0.0001
2022-05-29 00:53:52,837 - INFO] Train Epoch : 05 Loss:	 0.276268	 lr:0.0001
2022-05-29 00:56:00,873 - INFO] Train Epoch : 06 Loss:	 0.344316	 lr:0.0001
2022-05-29 00:58:08,674 - INFO] Train Epoch : 07 Loss:	 0.258545	 lr:0.0001
2022-05-29 01:00:18,547 - INFO] Train Epoch : 08 Loss:	 0.241049	 lr:0.0001
2022-05-29 01:02:27,291 - INFO] Train Epoch : 09 Loss:	 0.210682	 lr:0.0001
2022-05-29 01:04:35,756 - INFO] Train Epoch : 10 Loss:	 0.221957	 lr:0.0001
2022-05-29 01:06:44,161 - INFO] Train Epoch : 11 Loss:	 0.216700	 lr:0.0001
2022-05-29 01:08:52,544 - INFO] Train Epoch : 12 Loss:	 0.238847	 lr:0.0001
2022-05-29 01:11:01,150 - INFO] Train Epoch : 13 Loss:	 0.232199	 lr:0.0001
2022-05-29 01:13:08,508 - INFO] Train Epoch : 14 Loss:	 0.133918	 lr:0.0001
2022-05-29 01:15:17,958 - INFO] Train Epoch : 15 Loss:	 0.181406	 lr:0.0001
2022-05-29 01:17:26,031 - INFO] Train Epoch : 16 Loss:	 0.241289	 lr:0.0001
2022-05-29 01:19:34,324 - INFO] Train Epoch : 17 Loss:	 0.185698	 lr:0.0001
2022-05-29 01:21:42,826 - INFO] Train Epoch : 18 Loss:	 0.191058	 lr:0.0001
2022-05-29 01:23:50,362 - INFO] Train Epoch : 19 Loss:	 0.245448	 lr:0.0001
2022-05-29 01:25:59,489 - INFO] Train Epoch : 20 Loss:	 0.149253	 lr:0.0001
2022-05-29 01:28:07,718 - INFO] Train Epoch : 21 Loss:	 0.244539	 lr:0.0001
2022-05-29 01:30:17,267 - INFO] Train Epoch : 22 Loss:	 0.161647	 lr:0.0001
2022-05-29 01:32:25,876 - INFO] Train Epoch : 23 Loss:	 0.171847	 lr:0.0001
2022-05-29 01:34:34,201 - INFO] Train Epoch : 24 Loss:	 0.166180	 lr:0.0001
2022-05-29 01:36:42,452 - INFO] Train Epoch : 25 Loss:	 0.168052	 lr:0.0001
2022-05-29 01:38:52,278 - INFO] Train Epoch : 26 Loss:	 0.132793	 lr:0.0001
2022-05-29 01:41:01,952 - INFO] Train Epoch : 27 Loss:	 0.183349	 lr:0.0001
2022-05-29 01:43:10,535 - INFO] Train Epoch : 28 Loss:	 0.161334	 lr:0.0001
2022-05-29 01:45:18,975 - INFO] Train Epoch : 29 Loss:	 0.097157	 lr:0.0001
2022-05-29 01:47:27,812 - INFO] Train Epoch : 30 Loss:	 0.157271	 lr:0.0001
2022-05-29 01:49:37,144 - INFO] Train Epoch : 31 Loss:	 0.130937	 lr:0.0001
2022-05-29 01:51:46,524 - INFO] Train Epoch : 32 Loss:	 0.186382	 lr:0.0001
2022-05-29 01:53:54,839 - INFO] Train Epoch : 33 Loss:	 0.140781	 lr:0.0001
2022-05-29 01:56:03,493 - INFO] Train Epoch : 34 Loss:	 0.118996	 lr:0.0001
2022-05-29 01:58:11,556 - INFO] Train Epoch : 35 Loss:	 0.107619	 lr:0.0001
2022-05-29 02:00:21,453 - INFO] Train Epoch : 36 Loss:	 0.110400	 lr:0.0001
2022-05-29 02:02:29,963 - INFO] Train Epoch : 37 Loss:	 0.151315	 lr:0.0001
2022-05-29 02:04:37,773 - INFO] Train Epoch : 38 Loss:	 0.197235	 lr:0.0001
2022-05-29 02:06:46,825 - INFO] Train Epoch : 39 Loss:	 0.144048	 lr:0.0001
2022-05-29 02:08:55,216 - INFO] Train Epoch : 40 Loss:	 0.116058	 lr:0.0001
2022-05-29 02:11:03,763 - INFO] Train Epoch : 41 Loss:	 0.121000	 lr:0.0001
2022-05-29 02:13:11,595 - INFO] Train Epoch : 42 Loss:	 0.111576	 lr:0.0001
2022-05-29 02:15:20,065 - INFO] Train Epoch : 43 Loss:	 0.130003	 lr:0.0001
2022-05-29 02:17:28,255 - INFO] Train Epoch : 44 Loss:	 0.130733	 lr:0.0001
2022-05-29 02:19:36,247 - INFO] Train Epoch : 45 Loss:	 0.098546	 lr:0.0001
2022-05-29 02:21:44,067 - INFO] Train Epoch : 46 Loss:	 0.094261	 lr:0.0001
2022-05-29 02:23:51,413 - INFO] Train Epoch : 47 Loss:	 0.158808	 lr:0.0001
2022-05-29 02:25:59,239 - INFO] Train Epoch : 48 Loss:	 0.112948	 lr:0.0001
2022-05-29 02:28:09,126 - INFO] Train Epoch : 49 Loss:	 0.111580	 lr:0.0001
2022-05-29 02:30:17,572 - INFO] Train Epoch : 50 Loss:	 0.104452	 lr:0.0001
2022-05-29 02:32:27,075 - INFO] Train Epoch : 51 Loss:	 0.096878	 lr:0.0001
2022-05-29 02:34:35,466 - INFO] Train Epoch : 52 Loss:	 0.168689	 lr:0.0001
2022-05-29 02:36:44,001 - INFO] Train Epoch : 53 Loss:	 0.135409	 lr:0.0001
2022-05-29 02:38:53,972 - INFO] Train Epoch : 54 Loss:	 0.111991	 lr:0.0001
2022-05-29 02:41:01,732 - INFO] Train Epoch : 55 Loss:	 0.125626	 lr:0.0001
2022-05-29 02:43:09,481 - INFO] Train Epoch : 56 Loss:	 0.118539	 lr:0.0001
2022-05-29 02:45:17,906 - INFO] Train Epoch : 57 Loss:	 0.117114	 lr:0.0001
2022-05-29 02:47:26,806 - INFO] Train Epoch : 58 Loss:	 0.147084	 lr:0.0001
2022-05-29 02:49:35,161 - INFO] Train Epoch : 59 Loss:	 0.099669	 lr:0.0001
2022-05-29 02:51:43,461 - INFO] Train Epoch : 60 Loss:	 0.097668	 lr:0.0001
2022-05-29 02:53:51,579 - INFO] Train Epoch : 61 Loss:	 0.088971	 lr:0.0001
2022-05-29 02:55:59,562 - INFO] Train Epoch : 62 Loss:	 0.107359	 lr:0.0001
2022-05-29 02:58:07,404 - INFO] Train Epoch : 63 Loss:	 0.109295	 lr:0.0001
2022-05-29 03:00:15,318 - INFO] Train Epoch : 64 Loss:	 0.098938	 lr:0.0001
2022-05-29 03:02:23,090 - INFO] Train Epoch : 65 Loss:	 0.096089	 lr:0.0001
2022-05-29 03:04:31,507 - INFO] Train Epoch : 66 Loss:	 0.087491	 lr:0.0001
2022-05-29 03:06:39,158 - INFO] Train Epoch : 67 Loss:	 0.100319	 lr:0.0001
2022-05-29 03:08:47,402 - INFO] Train Epoch : 68 Loss:	 0.104837	 lr:0.0001
2022-05-29 03:10:55,387 - INFO] Train Epoch : 69 Loss:	 0.097597	 lr:0.0001
2022-05-29 03:13:04,588 - INFO] Train Epoch : 70 Loss:	 0.116584	 lr:0.0001
2022-05-29 03:15:12,620 - INFO] Train Epoch : 71 Loss:	 0.125111	 lr:0.0001
2022-05-29 03:17:20,816 - INFO] Train Epoch : 72 Loss:	 0.102033	 lr:0.0001
2022-05-29 03:19:29,629 - INFO] Train Epoch : 73 Loss:	 0.100465	 lr:0.0001
2022-05-29 03:21:37,564 - INFO] Train Epoch : 74 Loss:	 0.098886	 lr:0.0001
2022-05-29 03:23:44,415 - INFO] Train Epoch : 75 Loss:	 0.110282	 lr:0.0001
2022-05-29 03:25:51,600 - INFO] Train Epoch : 76 Loss:	 0.118997	 lr:0.0001
2022-05-29 03:27:59,867 - INFO] Train Epoch : 77 Loss:	 0.092708	 lr:0.0001
2022-05-29 03:30:08,175 - INFO] Train Epoch : 78 Loss:	 0.103450	 lr:0.0001
2022-05-29 03:32:17,259 - INFO] Train Epoch : 79 Loss:	 0.135171	 lr:0.0001
2022-05-29 03:34:25,729 - INFO] Train Epoch : 80 Loss:	 0.095389	 lr:0.0001
2022-05-29 03:36:33,331 - INFO] Train Epoch : 81 Loss:	 0.113264	 lr:0.0001
2022-05-29 03:38:41,161 - INFO] Train Epoch : 82 Loss:	 0.100730	 lr:0.0001
2022-05-29 03:40:50,197 - INFO] Train Epoch : 83 Loss:	 0.108749	 lr:0.0001
2022-05-29 03:42:58,160 - INFO] Train Epoch : 84 Loss:	 0.104925	 lr:0.0001
2022-05-29 03:45:06,691 - INFO] Train Epoch : 85 Loss:	 0.095446	 lr:0.0001
2022-05-29 03:47:15,172 - INFO] Train Epoch : 86 Loss:	 0.075079	 lr:0.0001
2022-05-29 03:49:23,657 - INFO] Train Epoch : 87 Loss:	 0.138791	 lr:0.0001
2022-05-29 03:51:31,802 - INFO] Train Epoch : 88 Loss:	 0.119682	 lr:0.0001
2022-05-29 03:53:40,527 - INFO] Train Epoch : 89 Loss:	 0.091519	 lr:0.0001
2022-05-29 03:55:48,437 - INFO] Train Epoch : 90 Loss:	 0.083878	 lr:0.0001
2022-05-29 03:57:57,157 - INFO] Train Epoch : 91 Loss:	 0.096723	 lr:0.0001
2022-05-29 04:00:05,228 - INFO] Train Epoch : 92 Loss:	 0.108683	 lr:0.0001
2022-05-29 04:02:13,911 - INFO] Train Epoch : 93 Loss:	 0.113670	 lr:0.0001
2022-05-29 04:04:22,821 - INFO] Train Epoch : 94 Loss:	 0.107115	 lr:0.0001
2022-05-29 04:06:31,531 - INFO] Train Epoch : 95 Loss:	 0.084605	 lr:0.0001
2022-05-29 04:08:39,501 - INFO] Train Epoch : 96 Loss:	 0.132085	 lr:0.0001
2022-05-29 04:10:49,198 - INFO] Train Epoch : 97 Loss:	 0.110878	 lr:0.0001
2022-05-29 04:12:57,886 - INFO] Train Epoch : 98 Loss:	 0.102944	 lr:0.0001
2022-05-29 04:15:05,202 - INFO] Train Epoch : 99 Loss:	 0.082790	 lr:0.0001
2022-05-29 04:17:12,623 - INFO] Train Epoch : 100 Loss:	 0.095377	 lr:0.0001
2022-05-29 04:19:20,152 - INFO] Train Epoch : 101 Loss:	 0.088221	 lr:0.0001
2022-05-29 04:21:27,857 - INFO] Train Epoch : 102 Loss:	 0.098754	 lr:0.0001
2022-05-29 04:23:35,872 - INFO] Train Epoch : 103 Loss:	 0.071059	 lr:0.0001
2022-05-29 04:25:45,230 - INFO] Train Epoch : 104 Loss:	 0.096289	 lr:0.0001
2022-05-29 04:27:53,846 - INFO] Train Epoch : 105 Loss:	 0.096531	 lr:0.0001
2022-05-29 04:30:01,956 - INFO] Train Epoch : 106 Loss:	 0.089407	 lr:0.0001
2022-05-29 04:32:11,435 - INFO] Train Epoch : 107 Loss:	 0.100626	 lr:0.0001
2022-05-29 04:34:20,614 - INFO] Train Epoch : 108 Loss:	 0.096956	 lr:0.0001
2022-05-29 04:36:30,399 - INFO] Train Epoch : 109 Loss:	 0.093171	 lr:0.0001
2022-05-29 04:38:38,625 - INFO] Train Epoch : 110 Loss:	 0.095930	 lr:0.0001
2022-05-29 04:40:47,258 - INFO] Train Epoch : 111 Loss:	 0.081484	 lr:0.0001
2022-05-29 04:42:55,412 - INFO] Train Epoch : 112 Loss:	 0.126297	 lr:0.0001
2022-05-29 04:45:03,507 - INFO] Train Epoch : 113 Loss:	 0.106694	 lr:0.0001
2022-05-29 04:47:11,697 - INFO] Train Epoch : 114 Loss:	 0.078152	 lr:0.0001
2022-05-29 04:49:21,618 - INFO] Train Epoch : 115 Loss:	 0.070837	 lr:0.0001
2022-05-29 04:51:30,194 - INFO] Train Epoch : 116 Loss:	 0.094106	 lr:0.0001
2022-05-29 04:53:37,868 - INFO] Train Epoch : 117 Loss:	 0.102929	 lr:0.0001
2022-05-29 04:55:48,075 - INFO] Train Epoch : 118 Loss:	 0.077138	 lr:0.0001
2022-05-29 04:57:56,155 - INFO] Train Epoch : 119 Loss:	 0.078986	 lr:0.0001
2022-05-29 05:00:05,666 - INFO] Train Epoch : 120 Loss:	 0.095601	 lr:0.0001
2022-05-29 05:02:13,886 - INFO] Train Epoch : 121 Loss:	 0.112015	 lr:0.0001
2022-05-29 05:04:22,563 - INFO] Train Epoch : 122 Loss:	 0.097104	 lr:0.0001
2022-05-29 05:06:31,889 - INFO] Train Epoch : 123 Loss:	 0.085594	 lr:0.0001
2022-05-29 05:08:40,087 - INFO] Train Epoch : 124 Loss:	 0.103563	 lr:0.0001
2022-05-29 05:10:49,642 - INFO] Train Epoch : 125 Loss:	 0.084641	 lr:0.0001
2022-05-29 05:12:58,285 - INFO] Train Epoch : 126 Loss:	 0.090719	 lr:0.0001
2022-05-29 05:15:06,720 - INFO] Train Epoch : 127 Loss:	 0.075382	 lr:0.0001
2022-05-29 05:17:15,175 - INFO] Train Epoch : 128 Loss:	 0.084695	 lr:0.0001
2022-05-29 05:19:23,575 - INFO] Train Epoch : 129 Loss:	 0.076245	 lr:0.0001
2022-05-29 05:21:32,358 - INFO] Train Epoch : 130 Loss:	 0.092979	 lr:0.0001
2022-05-29 05:23:42,710 - INFO] Train Epoch : 131 Loss:	 0.098303	 lr:0.0001
2022-05-29 05:25:51,737 - INFO] Train Epoch : 132 Loss:	 0.096954	 lr:0.0001
2022-05-29 05:28:00,140 - INFO] Train Epoch : 133 Loss:	 0.093772	 lr:0.0001
2022-05-29 05:30:07,173 - INFO] Train Epoch : 134 Loss:	 0.075570	 lr:0.0001
2022-05-29 05:32:15,509 - INFO] Train Epoch : 135 Loss:	 0.103216	 lr:0.0001
2022-05-29 05:34:23,968 - INFO] Train Epoch : 136 Loss:	 0.099711	 lr:0.0001
2022-05-29 05:36:32,277 - INFO] Train Epoch : 137 Loss:	 0.083023	 lr:0.0001
2022-05-29 05:38:40,596 - INFO] Train Epoch : 138 Loss:	 0.088792	 lr:0.0001
2022-05-29 05:40:48,583 - INFO] Train Epoch : 139 Loss:	 0.081146	 lr:0.0001
2022-05-29 05:42:56,767 - INFO] Train Epoch : 140 Loss:	 0.095657	 lr:0.0001
2022-05-29 05:45:06,270 - INFO] Train Epoch : 141 Loss:	 0.104599	 lr:0.0001
2022-05-29 05:47:14,834 - INFO] Train Epoch : 142 Loss:	 0.076407	 lr:0.0001
2022-05-29 05:49:23,349 - INFO] Train Epoch : 143 Loss:	 0.083967	 lr:0.0001
2022-05-29 05:51:32,016 - INFO] Train Epoch : 144 Loss:	 0.093228	 lr:0.0001
2022-05-29 05:53:41,836 - INFO] Train Epoch : 145 Loss:	 0.067450	 lr:0.0001
2022-05-29 05:55:50,345 - INFO] Train Epoch : 146 Loss:	 0.074286	 lr:0.0001
2022-05-29 05:57:58,402 - INFO] Train Epoch : 147 Loss:	 0.103826	 lr:0.0001
2022-05-29 06:00:07,926 - INFO] Train Epoch : 148 Loss:	 0.116908	 lr:0.0001
2022-05-29 06:02:16,096 - INFO] Train Epoch : 149 Loss:	 0.121939	 lr:0.0001
2022-05-29 06:04:22,626 - INFO] Train Epoch : 150 Loss:	 0.098966	 lr:0.0001
2022-05-29 06:06:29,456 - INFO] Train Epoch : 151 Loss:	 0.075442	 lr:0.0001
2022-05-29 06:08:37,356 - INFO] Train Epoch : 152 Loss:	 0.105000	 lr:0.0001
2022-05-29 06:10:45,846 - INFO] Train Epoch : 153 Loss:	 0.101675	 lr:0.0001
2022-05-29 06:12:52,803 - INFO] Train Epoch : 154 Loss:	 0.125336	 lr:0.0001
2022-05-29 06:14:59,234 - INFO] Train Epoch : 155 Loss:	 0.093724	 lr:0.0001
2022-05-29 06:17:05,324 - INFO] Train Epoch : 156 Loss:	 0.089601	 lr:0.0001
2022-05-29 06:19:13,677 - INFO] Train Epoch : 157 Loss:	 0.084322	 lr:0.0001
2022-05-29 06:21:21,712 - INFO] Train Epoch : 158 Loss:	 0.092516	 lr:0.0001
2022-05-29 06:23:30,179 - INFO] Train Epoch : 159 Loss:	 0.115474	 lr:0.0001
2022-05-29 06:25:37,532 - INFO] Train Epoch : 160 Loss:	 0.091063	 lr:0.0001
2022-05-29 06:27:43,780 - INFO] Train Epoch : 161 Loss:	 0.088159	 lr:0.0001
2022-05-29 06:29:48,767 - INFO] Train Epoch : 162 Loss:	 0.080487	 lr:0.0001
2022-05-29 06:31:54,953 - INFO] Train Epoch : 163 Loss:	 0.087662	 lr:0.0001
2022-05-29 06:34:02,433 - INFO] Train Epoch : 164 Loss:	 0.102592	 lr:0.0001
2022-05-29 06:36:08,485 - INFO] Train Epoch : 165 Loss:	 0.100249	 lr:0.0001
2022-05-29 06:38:17,001 - INFO] Train Epoch : 166 Loss:	 0.100096	 lr:0.0001
2022-05-29 06:40:25,628 - INFO] Train Epoch : 167 Loss:	 0.092486	 lr:0.0001
2022-05-29 06:42:33,414 - INFO] Train Epoch : 168 Loss:	 0.105195	 lr:0.0001
2022-05-29 06:44:41,797 - INFO] Train Epoch : 169 Loss:	 0.067341	 lr:0.0001
2022-05-29 06:46:50,094 - INFO] Train Epoch : 170 Loss:	 0.088467	 lr:0.0001
2022-05-29 06:48:58,515 - INFO] Train Epoch : 171 Loss:	 0.101266	 lr:0.0001
2022-05-29 06:51:06,704 - INFO] Train Epoch : 172 Loss:	 0.091050	 lr:0.0001
2022-05-29 06:53:14,307 - INFO] Train Epoch : 173 Loss:	 0.103923	 lr:0.0001
2022-05-29 06:55:22,544 - INFO] Train Epoch : 174 Loss:	 0.104064	 lr:0.0001
2022-05-29 06:57:30,861 - INFO] Train Epoch : 175 Loss:	 0.083016	 lr:0.0001
2022-05-29 06:59:40,026 - INFO] Train Epoch : 176 Loss:	 0.068641	 lr:0.0001
2022-05-29 07:01:48,757 - INFO] Train Epoch : 177 Loss:	 0.085485	 lr:0.0001
2022-05-29 07:03:57,829 - INFO] Train Epoch : 178 Loss:	 0.098094	 lr:0.0001
2022-05-29 07:06:06,018 - INFO] Train Epoch : 179 Loss:	 0.075175	 lr:0.0001
2022-05-29 07:08:14,256 - INFO] Train Epoch : 180 Loss:	 0.097248	 lr:0.0001
2022-05-29 07:10:22,770 - INFO] Train Epoch : 181 Loss:	 0.109250	 lr:0.0001
2022-05-29 07:12:30,198 - INFO] Train Epoch : 182 Loss:	 0.088873	 lr:0.0001
2022-05-29 07:14:36,471 - INFO] Train Epoch : 183 Loss:	 0.080522	 lr:0.0001
2022-05-29 07:16:44,133 - INFO] Train Epoch : 184 Loss:	 0.094580	 lr:0.0001
2022-05-29 07:18:53,000 - INFO] Train Epoch : 185 Loss:	 0.139025	 lr:0.0001
2022-05-29 07:21:01,589 - INFO] Train Epoch : 186 Loss:	 0.098588	 lr:0.0001
2022-05-29 07:23:09,828 - INFO] Train Epoch : 187 Loss:	 0.089251	 lr:0.0001
2022-05-29 07:25:19,113 - INFO] Train Epoch : 188 Loss:	 0.059334	 lr:0.0001
2022-05-29 07:27:28,244 - INFO] Train Epoch : 189 Loss:	 0.099699	 lr:0.0001
2022-05-29 07:29:36,253 - INFO] Train Epoch : 190 Loss:	 0.115501	 lr:0.0001
2022-05-29 07:31:41,778 - INFO] Train Epoch : 191 Loss:	 0.092224	 lr:0.0001
2022-05-29 07:33:49,812 - INFO] Train Epoch : 192 Loss:	 0.081098	 lr:0.0001
2022-05-29 07:35:56,361 - INFO] Train Epoch : 193 Loss:	 0.091598	 lr:0.0001
2022-05-29 07:38:01,721 - INFO] Train Epoch : 194 Loss:	 0.093091	 lr:0.0001
2022-05-29 07:40:08,939 - INFO] Train Epoch : 195 Loss:	 0.101571	 lr:0.0001
2022-05-29 07:42:14,769 - INFO] Train Epoch : 196 Loss:	 0.102765	 lr:0.0001
2022-05-29 07:44:20,432 - INFO] Train Epoch : 197 Loss:	 0.083789	 lr:0.0001
2022-05-29 07:46:27,011 - INFO] Train Epoch : 198 Loss:	 0.107958	 lr:0.0001
2022-05-29 07:48:35,020 - INFO] Train Epoch : 199 Loss:	 0.083103	 lr:0.0001
2022-06-01 07:42:41,594 - INFO] DVC training
2022-06-01 07:42:41,594 - INFO] config : 
2022-06-01 07:42:41,594 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-01 07:51:20,045 - INFO] DVC training
2022-06-01 07:51:20,045 - INFO] config : 
2022-06-01 07:51:20,046 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-01 07:52:08,849 - INFO] DVC training
2022-06-01 07:52:08,849 - INFO] config : 
2022-06-01 07:52:08,850 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-01 07:54:36,753 - INFO] DVC training
2022-06-01 07:54:36,753 - INFO] config : 
2022-06-01 07:54:36,754 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-01 08:00:17,213 - INFO] DVC training
2022-06-01 08:00:17,213 - INFO] config : 
2022-06-01 08:00:17,213 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-01 08:13:24,201 - INFO] DVC training
2022-06-01 08:13:24,201 - INFO] config : 
2022-06-01 08:13:24,201 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-01 08:15:19,150 - INFO] DVC training
2022-06-01 08:15:19,150 - INFO] config : 
2022-06-01 08:15:19,150 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-01 08:19:23,853 - INFO] DVC training
2022-06-01 08:19:23,853 - INFO] config : 
2022-06-01 08:19:23,854 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-01 08:23:41,113 - INFO] DVC training
2022-06-01 08:23:41,113 - INFO] config : 
2022-06-01 08:23:41,113 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-01 08:28:21,630 - INFO] DVC training
2022-06-01 08:28:21,630 - INFO] config : 
2022-06-01 08:28:21,630 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-01 08:30:37,467 - INFO] DVC training
2022-06-01 08:30:37,467 - INFO] config : 
2022-06-01 08:30:37,467 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-01 08:45:58,276 - INFO] DVC training
2022-06-01 08:45:58,276 - INFO] config : 
2022-06-01 08:45:58,276 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-01 08:48:19,044 - INFO] DVC training
2022-06-01 08:48:19,045 - INFO] config : 
2022-06-01 08:48:19,045 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 04:18:57,163 - INFO] DVC training
2022-06-03 04:18:57,163 - INFO] config : 
2022-06-03 04:18:57,163 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 04:21:23,333 - INFO] DVC training
2022-06-03 04:21:23,333 - INFO] config : 
2022-06-03 04:21:23,333 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 04:21:51,822 - INFO] DVC training
2022-06-03 04:21:51,822 - INFO] config : 
2022-06-03 04:21:51,823 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 04:27:40,053 - INFO] DVC training
2022-06-03 04:27:40,053 - INFO] config : 
2022-06-03 04:27:40,053 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 04:35:33,141 - INFO] DVC training
2022-06-03 04:35:33,142 - INFO] config : 
2022-06-03 04:35:33,142 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 04:36:23,516 - INFO] DVC training
2022-06-03 04:36:23,516 - INFO] config : 
2022-06-03 04:36:23,517 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 04:38:07,511 - INFO] DVC training
2022-06-03 04:38:07,511 - INFO] config : 
2022-06-03 04:38:07,511 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 04:40:29,378 - INFO] DVC training
2022-06-03 04:40:29,378 - INFO] config : 
2022-06-03 04:40:29,378 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 04:46:29,528 - INFO] DVC training
2022-06-03 04:46:29,528 - INFO] config : 
2022-06-03 04:46:29,528 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 04:48:07,585 - INFO] DVC training
2022-06-03 04:48:07,585 - INFO] config : 
2022-06-03 04:48:07,585 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 04:51:45,651 - INFO] DVC training
2022-06-03 04:51:45,651 - INFO] config : 
2022-06-03 04:51:45,652 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 04:52:53,381 - INFO] DVC training
2022-06-03 04:52:53,382 - INFO] config : 
2022-06-03 04:52:53,382 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 05:16:30,839 - INFO] DVC training
2022-06-03 05:16:30,839 - INFO] config : 
2022-06-03 05:16:30,839 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 05:20:02,411 - INFO] DVC training
2022-06-03 05:20:02,411 - INFO] config : 
2022-06-03 05:20:02,412 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 05:20:51,499 - INFO] DVC training
2022-06-03 05:20:51,499 - INFO] config : 
2022-06-03 05:20:51,499 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 05:21:37,716 - INFO] DVC training
2022-06-03 05:21:37,717 - INFO] config : 
2022-06-03 05:21:37,717 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 05:22:04,353 - INFO] DVC training
2022-06-03 05:22:04,353 - INFO] config : 
2022-06-03 05:22:04,353 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 06:37:38,591 - INFO] DVC training
2022-06-03 06:37:38,591 - INFO] config : 
2022-06-03 06:37:38,591 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 06:41:11,722 - INFO] DVC training
2022-06-03 06:41:11,722 - INFO] config : 
2022-06-03 06:41:11,722 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 06:45:02,863 - INFO] DVC training
2022-06-03 06:45:02,863 - INFO] config : 
2022-06-03 06:45:02,863 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 06:46:45,934 - INFO] DVC training
2022-06-03 06:46:45,934 - INFO] config : 
2022-06-03 06:46:45,934 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 06:48:08,387 - INFO] DVC training
2022-06-03 06:48:08,387 - INFO] config : 
2022-06-03 06:48:08,388 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 06:50:22,596 - INFO] DVC training
2022-06-03 06:50:22,596 - INFO] config : 
2022-06-03 06:50:22,596 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 07:04:04,024 - INFO] DVC training
2022-06-03 07:04:04,024 - INFO] config : 
2022-06-03 07:04:04,024 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 07:05:30,296 - INFO] DVC training
2022-06-03 07:05:30,296 - INFO] config : 
2022-06-03 07:05:30,297 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 07:07:00,063 - INFO] DVC training
2022-06-03 07:07:00,063 - INFO] config : 
2022-06-03 07:07:00,064 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 07:07:48,010 - INFO] DVC training
2022-06-03 07:07:48,010 - INFO] config : 
2022-06-03 07:07:48,010 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 07:11:19,462 - INFO] DVC training
2022-06-03 07:11:19,462 - INFO] config : 
2022-06-03 07:11:19,462 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 07:22:41,029 - INFO] DVC training
2022-06-03 07:22:41,030 - INFO] config : 
2022-06-03 07:22:41,030 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 07:33:20,694 - INFO] DVC training
2022-06-03 07:33:20,694 - INFO] config : 
2022-06-03 07:33:20,694 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 07:34:41,437 - INFO] DVC training
2022-06-03 07:34:41,437 - INFO] config : 
2022-06-03 07:34:41,437 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 08:09:52,417 - INFO] DVC training
2022-06-03 08:09:52,417 - INFO] config : 
2022-06-03 08:09:52,417 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 08:10:39,569 - INFO] DVC training
2022-06-03 08:10:39,569 - INFO] config : 
2022-06-03 08:10:39,569 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 08:12:10,401 - INFO] DVC training
2022-06-03 08:12:10,401 - INFO] config : 
2022-06-03 08:12:10,401 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 08:29:44,976 - INFO] DVC training
2022-06-03 08:29:44,976 - INFO] config : 
2022-06-03 08:29:44,976 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 08:37:15,022 - INFO] DVC training
2022-06-03 08:37:15,022 - INFO] config : 
2022-06-03 08:37:15,022 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 08:44:11,444 - INFO] DVC training
2022-06-03 08:44:11,444 - INFO] config : 
2022-06-03 08:44:11,444 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 08:44:36,593 - INFO] DVC training
2022-06-03 08:44:36,593 - INFO] config : 
2022-06-03 08:44:36,593 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 11:13:05,728 - INFO] DVC training
2022-06-03 11:13:05,728 - INFO] config : 
2022-06-03 11:13:05,728 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 11:14:28,693 - INFO] DVC training
2022-06-03 11:14:28,693 - INFO] config : 
2022-06-03 11:14:28,693 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 11:15:25,715 - INFO] DVC training
2022-06-03 11:15:25,716 - INFO] config : 
2022-06-03 11:15:25,716 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-03 11:33:00,901 - INFO] DVC training
2022-06-03 11:33:00,902 - INFO] config : 
2022-06-03 11:33:00,902 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-07 14:12:24,976 - INFO] DVC training
2022-06-07 14:12:24,976 - INFO] config : 
2022-06-07 14:12:24,976 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-07 14:19:38,556 - INFO] DVC training
2022-06-07 14:19:38,556 - INFO] config : 
2022-06-07 14:19:38,556 - INFO] {
    "tot_epoch": 100,
    "tot_step": 2000000,
    "train_lambda": 1024,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-07 14:22:42,257 - INFO] DVC training
2022-06-07 14:22:42,257 - INFO] config : 
2022-06-07 14:22:42,257 - INFO] {
    "tot_epoch": 100,
    "tot_step": 2000000,
    "train_lambda": 1024,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-07 14:24:45,754 - INFO] DVC training
2022-06-07 14:24:45,754 - INFO] config : 
2022-06-07 14:24:45,755 - INFO] {
    "tot_epoch": 100,
    "tot_step": 2000000,
    "train_lambda": 1024,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-06-07 14:27:04,987 - INFO] Train Epoch : 00 Loss:	 0.120298	 lr:0.0001
2022-06-07 14:29:20,267 - INFO] Train Epoch : 01 Loss:	 0.089942	 lr:0.0001
2022-06-07 14:31:33,566 - INFO] Train Epoch : 02 Loss:	 0.069049	 lr:0.0001
2022-06-07 14:33:47,503 - INFO] Train Epoch : 03 Loss:	 0.069754	 lr:0.0001
2022-06-07 14:36:01,668 - INFO] Train Epoch : 04 Loss:	 0.061037	 lr:0.0001
2022-06-07 14:38:14,673 - INFO] Train Epoch : 05 Loss:	 0.045335	 lr:0.0001
2022-06-07 14:40:28,479 - INFO] Train Epoch : 06 Loss:	 0.050459	 lr:0.0001
2022-06-07 14:42:42,071 - INFO] Train Epoch : 07 Loss:	 0.027147	 lr:0.0001
2022-06-07 14:44:55,424 - INFO] Train Epoch : 08 Loss:	 0.062070	 lr:0.0001
2022-06-07 14:47:09,318 - INFO] Train Epoch : 09 Loss:	 0.028384	 lr:0.0001
2022-06-07 14:49:23,504 - INFO] Train Epoch : 10 Loss:	 0.022636	 lr:0.0001
2022-06-07 14:51:37,305 - INFO] Train Epoch : 11 Loss:	 0.029124	 lr:0.0001
2022-06-07 14:53:51,413 - INFO] Train Epoch : 12 Loss:	 0.031183	 lr:0.0001
2022-06-07 14:56:05,686 - INFO] Train Epoch : 13 Loss:	 0.029509	 lr:0.0001
2022-06-07 14:58:19,423 - INFO] Train Epoch : 14 Loss:	 0.025422	 lr:0.0001
2022-06-07 15:00:33,156 - INFO] Train Epoch : 15 Loss:	 0.021683	 lr:0.0001
2022-06-07 15:02:47,436 - INFO] Train Epoch : 16 Loss:	 0.023521	 lr:0.0001
2022-06-07 15:05:02,001 - INFO] Train Epoch : 17 Loss:	 0.016416	 lr:0.0001
2022-06-07 15:07:16,057 - INFO] Train Epoch : 18 Loss:	 0.027298	 lr:0.0001
2022-06-07 15:09:29,419 - INFO] Train Epoch : 19 Loss:	 0.021678	 lr:0.0001
2022-06-07 15:11:43,210 - INFO] Train Epoch : 20 Loss:	 0.025596	 lr:0.0001
2022-06-07 15:13:56,831 - INFO] Train Epoch : 21 Loss:	 0.022214	 lr:0.0001
2022-06-07 15:16:10,757 - INFO] Train Epoch : 22 Loss:	 0.023294	 lr:0.0001
2022-06-07 15:18:23,946 - INFO] Train Epoch : 23 Loss:	 0.026166	 lr:0.0001
2022-06-07 15:20:37,536 - INFO] Train Epoch : 24 Loss:	 0.019492	 lr:0.0001
2022-06-07 15:22:50,744 - INFO] Train Epoch : 25 Loss:	 0.021148	 lr:0.0001
2022-06-07 15:25:03,522 - INFO] Train Epoch : 26 Loss:	 0.018628	 lr:0.0001
2022-06-07 15:27:17,347 - INFO] Train Epoch : 27 Loss:	 0.019911	 lr:0.0001
2022-06-07 15:29:31,700 - INFO] Train Epoch : 28 Loss:	 0.017804	 lr:0.0001
2022-06-07 15:31:44,955 - INFO] Train Epoch : 29 Loss:	 0.016984	 lr:0.0001
2022-06-07 15:33:58,189 - INFO] Train Epoch : 30 Loss:	 0.018170	 lr:0.0001
2022-06-07 15:36:11,681 - INFO] Train Epoch : 31 Loss:	 0.015741	 lr:0.0001
2022-06-07 15:38:25,711 - INFO] Train Epoch : 32 Loss:	 0.023685	 lr:0.0001
2022-06-07 15:40:39,650 - INFO] Train Epoch : 33 Loss:	 0.019375	 lr:0.0001
2022-06-07 15:42:53,765 - INFO] Train Epoch : 34 Loss:	 0.019150	 lr:0.0001
2022-06-07 15:45:07,463 - INFO] Train Epoch : 35 Loss:	 0.018653	 lr:0.0001
2022-06-07 15:47:20,606 - INFO] Train Epoch : 36 Loss:	 0.015609	 lr:0.0001
2022-06-07 15:49:34,039 - INFO] Train Epoch : 37 Loss:	 0.018593	 lr:0.0001
2022-06-07 15:51:47,405 - INFO] Train Epoch : 38 Loss:	 0.021609	 lr:0.0001
2022-06-07 15:54:00,672 - INFO] Train Epoch : 39 Loss:	 0.021890	 lr:0.0001
2022-06-07 15:56:14,610 - INFO] Train Epoch : 40 Loss:	 0.016601	 lr:0.0001
2022-06-07 15:58:28,589 - INFO] Train Epoch : 41 Loss:	 0.016727	 lr:0.0001
2022-06-07 16:00:42,475 - INFO] Train Epoch : 42 Loss:	 0.015653	 lr:0.0001
2022-06-07 16:02:55,921 - INFO] Train Epoch : 43 Loss:	 0.020925	 lr:0.0001
2022-06-07 16:05:10,601 - INFO] Train Epoch : 44 Loss:	 0.018011	 lr:0.0001
2022-06-07 16:07:23,522 - INFO] Train Epoch : 45 Loss:	 0.018219	 lr:0.0001
2022-06-07 16:09:40,066 - INFO] Train Epoch : 46 Loss:	 0.019372	 lr:0.0001
2022-06-07 16:11:54,254 - INFO] Train Epoch : 47 Loss:	 0.015555	 lr:0.0001
2022-06-07 16:14:08,275 - INFO] Train Epoch : 48 Loss:	 0.019753	 lr:0.0001
2022-06-07 16:16:23,012 - INFO] Train Epoch : 49 Loss:	 0.017504	 lr:0.0001
2022-06-07 16:18:36,894 - INFO] Train Epoch : 50 Loss:	 0.022316	 lr:0.0001
2022-06-07 16:20:51,227 - INFO] Train Epoch : 51 Loss:	 0.016806	 lr:0.0001
2022-06-07 16:23:05,807 - INFO] Train Epoch : 52 Loss:	 0.014459	 lr:0.0001
2022-06-07 16:25:20,483 - INFO] Train Epoch : 53 Loss:	 0.015294	 lr:0.0001
2022-06-07 16:27:35,581 - INFO] Train Epoch : 54 Loss:	 0.017277	 lr:0.0001
2022-06-07 16:29:49,568 - INFO] Train Epoch : 55 Loss:	 0.019643	 lr:0.0001
2022-06-07 16:32:04,306 - INFO] Train Epoch : 56 Loss:	 0.012860	 lr:0.0001
2022-06-07 16:34:19,472 - INFO] Train Epoch : 57 Loss:	 0.021407	 lr:0.0001
2022-06-07 16:36:34,855 - INFO] Train Epoch : 58 Loss:	 0.019241	 lr:0.0001
2022-06-07 16:38:49,142 - INFO] Train Epoch : 59 Loss:	 0.021784	 lr:0.0001
2022-06-07 16:41:05,353 - INFO] Train Epoch : 60 Loss:	 0.019654	 lr:0.0001
2022-06-07 16:43:21,261 - INFO] Train Epoch : 61 Loss:	 0.015099	 lr:0.0001
2022-06-07 16:45:36,882 - INFO] Train Epoch : 62 Loss:	 0.019784	 lr:0.0001
2022-06-07 16:47:52,843 - INFO] Train Epoch : 63 Loss:	 0.016939	 lr:0.0001
2022-06-07 16:50:05,570 - INFO] Train Epoch : 64 Loss:	 0.013615	 lr:0.0001
2022-06-07 16:52:17,094 - INFO] Train Epoch : 65 Loss:	 0.014696	 lr:0.0001
2022-06-07 16:54:28,671 - INFO] Train Epoch : 66 Loss:	 0.017543	 lr:0.0001
2022-06-07 16:56:44,037 - INFO] Train Epoch : 67 Loss:	 0.016176	 lr:0.0001
2022-06-07 16:58:54,549 - INFO] Train Epoch : 68 Loss:	 0.018349	 lr:0.0001
2022-06-07 17:01:05,213 - INFO] Train Epoch : 69 Loss:	 0.016560	 lr:0.0001
2022-06-07 17:03:15,991 - INFO] Train Epoch : 70 Loss:	 0.015284	 lr:0.0001
2022-06-07 17:05:26,646 - INFO] Train Epoch : 71 Loss:	 0.016978	 lr:0.0001
2022-06-07 17:07:39,243 - INFO] Train Epoch : 72 Loss:	 0.016059	 lr:0.0001
2022-06-07 17:09:51,310 - INFO] Train Epoch : 73 Loss:	 0.017073	 lr:0.0001
2022-06-07 17:12:00,963 - INFO] Train Epoch : 74 Loss:	 0.018939	 lr:0.0001
2022-06-07 17:14:13,527 - INFO] Train Epoch : 75 Loss:	 0.015334	 lr:0.0001
2022-06-07 17:16:26,336 - INFO] Train Epoch : 76 Loss:	 0.013624	 lr:0.0001
2022-06-07 17:18:38,900 - INFO] Train Epoch : 77 Loss:	 0.015217	 lr:0.0001
2022-06-07 17:20:52,222 - INFO] Train Epoch : 78 Loss:	 0.016327	 lr:0.0001
2022-06-07 17:23:06,179 - INFO] Train Epoch : 79 Loss:	 0.014727	 lr:0.0001
2022-06-07 17:25:23,797 - INFO] Train Epoch : 80 Loss:	 0.018119	 lr:0.0001
2022-06-07 17:27:38,668 - INFO] Train Epoch : 81 Loss:	 0.015490	 lr:0.0001
2022-06-07 17:29:53,380 - INFO] Train Epoch : 82 Loss:	 0.016604	 lr:0.0001
2022-06-07 17:32:07,917 - INFO] Train Epoch : 83 Loss:	 0.014355	 lr:0.0001
2022-06-07 17:34:23,457 - INFO] Train Epoch : 84 Loss:	 0.027460	 lr:0.0001
2022-06-07 17:36:37,683 - INFO] Train Epoch : 85 Loss:	 0.013089	 lr:0.0001
2022-06-07 17:38:51,852 - INFO] Train Epoch : 86 Loss:	 0.014261	 lr:0.0001
2022-06-07 17:41:07,235 - INFO] Train Epoch : 87 Loss:	 0.014206	 lr:0.0001
2022-06-07 17:43:21,497 - INFO] Train Epoch : 88 Loss:	 0.020986	 lr:0.0001
2022-06-07 17:45:35,377 - INFO] Train Epoch : 89 Loss:	 0.017953	 lr:0.0001
2022-06-07 17:47:51,046 - INFO] Train Epoch : 90 Loss:	 0.012545	 lr:0.0001
2022-06-07 17:50:05,283 - INFO] Train Epoch : 91 Loss:	 0.013346	 lr:0.0001
2022-06-07 17:52:20,402 - INFO] Train Epoch : 92 Loss:	 0.019265	 lr:0.0001
2022-06-07 17:54:35,880 - INFO] Train Epoch : 93 Loss:	 0.010843	 lr:0.0001
2022-06-07 17:56:50,737 - INFO] Train Epoch : 94 Loss:	 0.014514	 lr:0.0001
2022-06-07 17:59:02,956 - INFO] Train Epoch : 95 Loss:	 0.013527	 lr:0.0001
2022-06-07 18:01:14,375 - INFO] Train Epoch : 96 Loss:	 0.013340	 lr:0.0001
2022-06-07 18:03:24,835 - INFO] Train Epoch : 97 Loss:	 0.021432	 lr:0.0001
2022-06-07 18:05:40,902 - INFO] Train Epoch : 98 Loss:	 0.020120	 lr:0.0001
2022-06-07 18:07:52,466 - INFO] Train Epoch : 99 Loss:	 0.015355	 lr:0.0001
